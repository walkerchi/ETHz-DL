dataset.name    = 'MSCOCO'
models.name     = ['HuggingFacePrunedCLIP','HuggingFaceCLIP']
base_model.name = ['HuggingFaceCLIP']
topk            = [1, 5, 10]
topm            = [50]
seed            = 123456789
logging_level   = 'INFO'
device          = 'cpu'
batch_size      = 32
cache_type      = "dense"
experiment      = "topk"

[dataset.kwargs]
layout    = 'image-caption[0]'

[models.0.kwargs]
model_str = 'openai/clip-vit-base-patch16'
pruning_version = '<path to your fisher-pruned model with p=0.6 (constraint=0.4)>'

[models.1.kwargs]
model_str = 'openai/clip-vit-base-patch16'


