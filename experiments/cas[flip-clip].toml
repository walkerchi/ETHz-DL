#[OpenAIFLIP, OpenAICLIP]
dataset.name    = 'MSCOCO'
models.name     = ['HuggingFaceFLIP', 'HuggingFaceCLIP']
topk            = [1, 5, 10]
topm            = [50]
seed            = 123456789
logging_level   = 'INFO'
device          = 'cuda:0'
f      = 0.01
batch_size      = 2
cache_type      = "sparse"

[dataset.kwargs]
n_samples       = 500
layout    = 'image-caption[0]'

[models.0.kwargs]
p         = 0.5
model_str = "openai/clip-vit-base-patch32"

[models.1.kwargs]
model_str = "openai/clip-vit-base-patch32"
